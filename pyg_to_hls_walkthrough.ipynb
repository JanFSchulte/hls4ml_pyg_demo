{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bc2776",
   "metadata": {},
   "source": [
    "# Installation\n",
    "Please follow the instructions on README.mk file for installing the necessary packages to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b78f5f",
   "metadata": {},
   "source": [
    "This walkthrough has few instructions. It's mainly just code to help the user to understand the pytorch geometric to hls4ml pipeline. If there's any confusion, please email me at yun79@purdue.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1907e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e745ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handler args: ('NodeBlock',)\n",
      "handler args: ('EdgeAggregate',)\n",
      "handler args: ('ResidualBlock',)\n",
      "handler args: ('NodeEncoder',)\n",
      "handler args: ('EdgeEncoder',)\n",
      "handler args: ('NodeEncoderBatchNorm1d',)\n",
      "handler args: ('EdgeEncoderBatchNorm1d',)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from hls4ml.utils.config import config_from_pyg_model\n",
    "from hls4ml.converters import convert_from_pyg_model\n",
    "import hls4ml\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# locals\n",
    "from utils.models.interaction_network_pyg import GENConvBig\n",
    "from model_wrappers import model_wrapper\n",
    "from utils.data.dataset_pyg import GraphDataset\n",
    "from utils.data.fix_graph_size import fix_graph_size\n",
    "import time\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb118bac",
   "metadata": {},
   "source": [
    "### PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24082fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We intialize our custom pytorch geometric(pyg) model\n",
    "\"\"\"\n",
    "n_layers = 2\n",
    "torch_model = GENConvBig(\n",
    "    n_layers, \n",
    "    flow = \"source_to_target\",\n",
    "    out_channels = 128,\n",
    "    debugging = True\n",
    ").eval() # eval mode for bathnorm\n",
    "\"\"\"\n",
    "We obtain the state dict(trained parameters) from Siqi Miao, PhD student of Prof Pan Li\n",
    "\"\"\"\n",
    "state_dict = torch.load('./model.pt', map_location=\"cpu\")\n",
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ffa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load/transfer the state dict into our pyg model\n",
    "\"\"\"\n",
    "\n",
    "# print(type(torch_model.node_encoder.weight))\n",
    "# print(type(siqi_model_state_dict['model_state_dict']['node_encoder.weight']))\n",
    "torch_model.node_encoder.weight = nn.Parameter(state_dict['model_state_dict']['node_encoder.weight'])\n",
    "torch_model.node_encoder.bias = nn.Parameter(state_dict['model_state_dict']['node_encoder.bias'])\n",
    "torch_model.edge_encoder.weight = nn.Parameter(state_dict['model_state_dict']['edge_encoder.weight'])\n",
    "torch_model.edge_encoder.bias = nn.Parameter(state_dict['model_state_dict']['edge_encoder.bias'])\n",
    "torch_model.node_encoder_norm.weight = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_node_feature.weight']\n",
    ")\n",
    "torch_model.node_encoder_norm.norm.weight = torch_model.node_encoder_norm.weight # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.node_encoder_norm.bias = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_node_feature.bias']\n",
    ")\n",
    "torch_model.node_encoder_norm.norm.bias = torch_model.node_encoder_norm.bias # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.node_encoder_norm.running_mean = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_node_feature.running_mean']\n",
    ")\n",
    "torch_model.node_encoder_norm.norm.running_mean = torch_model.node_encoder_norm.running_mean # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.node_encoder_norm.running_var = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_node_feature.running_var']\n",
    ")\n",
    "torch_model.node_encoder_norm.norm.running_var = torch_model.node_encoder_norm.running_var # this is temporary soln to the structure of the class\n",
    "\n",
    "\n",
    "torch_model.edge_encoder_norm.weight = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_edge_feature.weight']\n",
    ")\n",
    "torch_model.edge_encoder_norm.norm.weight = torch_model.edge_encoder_norm.weight # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.edge_encoder_norm.bias = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_edge_feature.bias']\n",
    ")\n",
    "torch_model.edge_encoder_norm.norm.bias = torch_model.edge_encoder_norm.bias # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.edge_encoder_norm.running_mean = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_edge_feature.running_mean']\n",
    ")\n",
    "torch_model.edge_encoder_norm.norm.running_mean = torch_model.edge_encoder_norm.running_mean # this is temporary soln to the structure of the class\n",
    "\n",
    "torch_model.edge_encoder_norm.running_var = nn.Parameter(\n",
    "    state_dict['model_state_dict']['bn_edge_feature.running_var']\n",
    ")\n",
    "torch_model.edge_encoder_norm.norm.running_var = torch_model.edge_encoder_norm.running_var # this is temporary soln to the structure of the class\n",
    "\n",
    "# now the nodeblocks and betas\n",
    "original_layer_idxs = [0,1,4] # don't ask me why it jumps from 1 to 4\n",
    "new_layer_mlp_idxs = [0,1,3] # we skip 2 bc that's activation\n",
    "Betas = []\n",
    "for nodeblock_idx in range(n_layers):\n",
    "    gnn = torch_model.gnns[nodeblock_idx]\n",
    "    gnn.beta = state_dict['model_state_dict'][f'convs.{nodeblock_idx}.t']\n",
    "    Betas.append(float(gnn.beta[0]))\n",
    "    \n",
    "    mlp_name = f\"mlps.{nodeblock_idx}.\"\n",
    "    \n",
    "    for idx in range(len(original_layer_idxs)):\n",
    "        original_layer_idx = original_layer_idxs[idx]\n",
    "        new_layer_mlp_idx = new_layer_mlp_idxs[idx]\n",
    "        nodeblock_name = f\"O_{nodeblock_idx}\"\n",
    "        nodeblock = getattr(torch_model, nodeblock_name)\n",
    "        module = nodeblock.layers[new_layer_mlp_idx]\n",
    "        if (module.__class__.__name__ == 'Linear') or (module.__class__.__name__ == 'BatchNorm1d'):\n",
    "            module.weight = nn.Parameter(\n",
    "                state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.weight\"]\n",
    "            )\n",
    "            module.bias = nn.Parameter(\n",
    "                state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.bias\"]\n",
    "            )\n",
    "        if (module.__class__.__name__ == 'BatchNorm1d'):\n",
    "            module.running_mean = nn.Parameter(\n",
    "                state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.running_mean\"]\n",
    "            )\n",
    "            module.running_var = nn.Parameter(\n",
    "                state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.running_var\"]\n",
    "            )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a122813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta loading for layer 2 successful: tensor([True])\n",
      "weight loading for layer 0 successful: True\n",
      "bias loading for layer 0 successful: True\n",
      "weight loading for layer 1 successful: True\n",
      "bias loading for layer 1 successful: True\n",
      "running_mean loading for layer 1 successful: True\n",
      "running_var loading for layer 1 successful: True\n",
      "weight loading for layer 2 successful: True\n",
      "bias loading for layer 2 successful: True\n",
      "beta loading for layer 2 successful: tensor([True])\n",
      "weight loading for layer 0 successful: True\n",
      "bias loading for layer 0 successful: True\n",
      "weight loading for layer 1 successful: True\n",
      "bias loading for layer 1 successful: True\n",
      "running_mean loading for layer 1 successful: True\n",
      "running_var loading for layer 1 successful: True\n",
      "weight loading for layer 2 successful: True\n",
      "bias loading for layer 2 successful: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Just some code to test if the transfer was successful\n",
    "\"\"\"\n",
    "for nodeblock_idx in range(n_layers):\n",
    "    gnn = torch_model.gnns[nodeblock_idx]\n",
    "    boolean_val = gnn.beta == state_dict['model_state_dict'][f'convs.{nodeblock_idx}.t']\n",
    "#     print(f\"beta: {gnn.beta}\")\n",
    "    print(f\"beta loading for layer {idx} successful: {boolean_val}\")\n",
    "    \n",
    "    mlp_name = f\"mlps.{nodeblock_idx}.\"\n",
    "    for idx in range(len(original_layer_idxs)):\n",
    "        original_layer_idx = original_layer_idxs[idx]\n",
    "        new_layer_mlp_idx = new_layer_mlp_idxs[idx]\n",
    "        nodeblock_name = f\"O_{nodeblock_idx}\"\n",
    "        nodeblock = getattr(torch_model, nodeblock_name)\n",
    "        module = nodeblock.layers[new_layer_mlp_idx]\n",
    "        if (module.__class__.__name__ == 'Linear') or (module.__class__.__name__ == 'BatchNorm1d'):\n",
    "            boolean_val = torch.all(\n",
    "                module.state_dict()[\"weight\"] == state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.weight\"]\n",
    "            )\n",
    "            print(f\"weight loading for layer {idx} successful: {boolean_val}\")\n",
    "            \n",
    "            boolean_val = torch.all(\n",
    "                module.state_dict()[\"bias\"] == state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.bias\"]\n",
    "            )\n",
    "            print(f\"bias loading for layer {idx} successful: {boolean_val}\")\n",
    "            \n",
    "        if (module.__class__.__name__ == 'BatchNorm1d'):\n",
    "            boolean_val = torch.all(\n",
    "                module.state_dict()[\"running_mean\"] == state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.running_mean\"]\n",
    "            )\n",
    "            print(f\"running_mean loading for layer {idx} successful: {boolean_val}\")\n",
    "            \n",
    "            boolean_val = torch.all(\n",
    "                module.state_dict()[\"running_var\"] == state_dict['model_state_dict'][mlp_name+f\"{original_layer_idx}.running_var\"]\n",
    "            )\n",
    "            print(f\"running_var loading for layer {idx} successful: {boolean_val}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49e754",
   "metadata": {},
   "source": [
    "### HLS Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497dd99",
   "metadata": {},
   "source": [
    "hls4ml cannot infer the *order* in which these submodules are called within the pytorch model's \"forward()\" function. We have to manually define this information in the form of an ordered-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b64da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward_dict: defines the order in which graph-blocks are called in the model's 'forward()' method\n",
    "\"\"\"\n",
    "forward_dict = OrderedDict()\n",
    "forward_dict[\"node_encoder\"] = \"NodeEncoder\"\n",
    "forward_dict[\"edge_encoder\"] = \"EdgeEncoder\"\n",
    "forward_dict[\"node_encoder_norm\"] = \"NodeEncoderBatchNorm1d\"\n",
    "forward_dict[\"edge_encoder_norm\"] = \"EdgeEncoderBatchNorm1d\"\n",
    "for nodeblock_idx in range(n_layers):\n",
    "    forward_dict[f\"O_{nodeblock_idx}\"] = \"NodeBlock\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf43159",
   "metadata": {},
   "source": [
    "hls4ml creates a hardware implementation of the GNN, which can only be represented using fixed-size arrays. This restriction also applies to the inputs and outputs of the GNN, so we must define the size of the graphs that this hardware GNN can take as input**, again in the form of a dictionary. \n",
    "\n",
    "**Graphs of a different size can be padded or truncated to the appropriate size using the \"fix_graph_size\" function. In this notebook, padding/truncation is  done in the \"Data\" cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa5a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we define additional parameters.\n",
    "\"\"\"\n",
    "common_dim = 128\n",
    "graph_dims = {\n",
    "        \"n_node\": 28,\n",
    "        \"n_edge\": 37,\n",
    "        \"node_attr\": 3,\n",
    "        \"node_dim\": common_dim,\n",
    "        \"edge_attr\": 4,\n",
    "    \"edge_dim\":common_dim\n",
    "}\n",
    "\n",
    "misc_config = {\"Betas\" : Betas}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943157a",
   "metadata": {},
   "source": [
    "Armed with our pytorch model and these two dictionaries**, we can create the HLS model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59aa1957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'Model': {'Precision': 'ap_fixed<52,20>', 'IndexPrecision': 'ap_uint<16>', 'ReuseFactor': 8, 'Strategy': 'Latency'}}\n",
      "misc_config: {'Betas': [3.8588860034942627, 1.0975205898284912]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We initialize hls model from pyg model\n",
    "\"\"\"\n",
    "output_dir = \"test_GNN\"\n",
    "config = config_from_pyg_model(torch_model,\n",
    "                                   default_precision=\"ap_fixed<52,20>\",\n",
    "                                   default_index_precision='ap_uint<16>', \n",
    "                                   default_reuse_factor=8)\n",
    "print(f\"config: {config}\")\n",
    "hls_model = convert_from_pyg_model(torch_model,\n",
    "                                       n_edge=graph_dims['n_edge'],\n",
    "                                       n_node=graph_dims['n_node'],\n",
    "                                       edge_attr=graph_dims['edge_attr'],\n",
    "                                       node_attr=graph_dims['node_attr'],\n",
    "                                       edge_dim=graph_dims['edge_dim'],\n",
    "                                       node_dim=graph_dims['node_dim'],\n",
    "                                       misc_config = misc_config,\n",
    "                                       forward_dictionary=forward_dict, \n",
    "                                       activate_final='sigmoid', #sigmoid\n",
    "                                       output_dir=output_dir,\n",
    "                                       hls_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0701c",
   "metadata": {},
   "source": [
    "## hls_model.compile() builds the C-function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da705cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "lib_name: firmware/myproject-2dA499f2.so\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678b04",
   "metadata": {},
   "source": [
    "# Evaluation and prediction: hls_model.predict(input)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e31a4c5a",
   "metadata": {},
   "source": [
    "If your model takes a non-singular input (e.g. node attributes, edge attributes, and an edge index), then you should pass it as a list (e.g. [node_attr, edge_attr, edge_index]). See the \"data_wrapper\" class, and note that the hls_model.predict() method is used on the data.hls_data attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c3eaa",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4856a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS: [0 1 2 3 4 5 6 7 8 9]\n",
      "graphs length: 12\n",
      "writing test bench data for 1st graph\n"
     ]
    }
   ],
   "source": [
    "class data_wrapper(object):\n",
    "    def __init__(self, node_attr, edge_attr, edge_index, target):\n",
    "        self.x = node_attr\n",
    "        self.edge_attr = edge_attr\n",
    "        self.edge_index = edge_index.transpose(0,1)\n",
    "\n",
    "        node_attr, edge_attr, edge_index = self.x.detach().cpu().numpy(), self.edge_attr.detach().cpu().numpy(), self.edge_index.transpose(0, 1).detach().cpu().numpy().astype(np.float32)\n",
    "        node_attr, edge_attr, edge_index = np.ascontiguousarray(node_attr), np.ascontiguousarray(edge_attr), np.ascontiguousarray(edge_index)\n",
    "        self.hls_data = [node_attr, edge_attr, edge_index]\n",
    "\n",
    "        self.target = target\n",
    "        self.np_target = np.reshape(target.detach().cpu().numpy(), newshape=(target.shape[0],))\n",
    "\n",
    "def load_graphs(graph_indir, graph_dims, n_graphs):\n",
    "    graph_files = np.array(os.listdir(graph_indir))\n",
    "    graph_files = np.array([os.path.join(graph_indir, graph_file)\n",
    "                            for graph_file in graph_files])\n",
    "    n_graphs_total = len(graph_files)\n",
    "    IDs = np.arange(n_graphs_total)\n",
    "    print(f\"IDS: {IDs}\")\n",
    "    dataset = GraphDataset(graph_files=graph_files[IDs])\n",
    "\n",
    "    graphs = []\n",
    "    for data in dataset[:n_graphs]:\n",
    "        node_attr, edge_attr, edge_index, target, bad_graph = fix_graph_size(data.x, data.edge_attr, data.edge_index,\n",
    "                                                                             data.y,\n",
    "                                                                             n_node_max=graph_dims['n_node'],\n",
    "                                                                             n_edge_max=graph_dims['n_edge'])\n",
    "        if not bad_graph:\n",
    "            graphs.append(data_wrapper(node_attr, edge_attr, edge_index, target))\n",
    "        graphs.append(data_wrapper(node_attr, edge_attr, edge_index, target))\n",
    "    print(f\"graphs length: {len(graphs)}\")\n",
    "\n",
    "    print(\"writing test bench data for 1st graph\")\n",
    "    data = graphs[0]\n",
    "    node_attr, edge_attr, edge_index = data.x.detach().cpu().numpy(), data.edge_attr.detach().cpu().numpy(), data.edge_index.transpose(\n",
    "        0, 1).detach().cpu().numpy().astype(np.int32)\n",
    "    os.makedirs('tb_data', exist_ok=True)\n",
    "    input_data = np.concatenate([node_attr.reshape(1, -1), edge_attr.reshape(1, -1), edge_index.reshape(1, -1)], axis=1)\n",
    "    np.savetxt('tb_data/input_data.dat', input_data, fmt='%f', delimiter=' ')\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "graph_indir = \"trackml_data/processed_plus_pyg_small\"\n",
    "\n",
    "graphs = load_graphs(graph_indir, graph_dims, n_graphs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351c75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_l: [1.14779347e-07 1.14779347e-07 1.20809972e-07 1.16126657e-07\n",
      " 1.16136640e-07 1.16136640e-07 1.23966146e-07 1.14714169e-07\n",
      " 3.21942196e-07 1.20112787e-07 1.47282591e-07 1.13777716e-07]\n",
      "Mean of all MSEs: 1.367136803764879e-07\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we are testing hls model output compared to pyg model.\n",
    "We are using Mean Squared Error (MSE) to calculate the differences \n",
    "in the output of the two models.\n",
    "\"\"\"\n",
    "MSE_l = []\n",
    "for data in graphs:\n",
    "    torch_pred = torch_model(data)\n",
    "    torch_pred = torch_pred.detach().cpu().numpy().flatten()\n",
    "    hls_pred = hls_model.predict(data.hls_data)\n",
    "    MSE = mean_squared_error(torch_pred, hls_pred)\n",
    "    MSE_l.append(MSE)\n",
    "\n",
    "MSE_l = np.array(MSE_l)\n",
    "print(f\"MSE_l: {MSE_l}\")\n",
    "print(f\"Mean of all MSEs: {np.mean(MSE_l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b1428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSEs: \n",
      " [1.5790106e-07, 1.7490449e-07, 1.4319428e-07, 1.3813825e-07, 1.5853026e-07, 1.5185257e-07, 1.4170519e-07, 1.4666254e-07, 1.4777571e-07, 1.14496984e-07, 1.5975017e-07, 1.14986435e-07, 1.5552736e-07, 1.6860555e-07, 1.6011543e-07, 1.3972682e-07, 1.427125e-07, 1.5337447e-07, 1.5065207e-07, 1.364838e-07]\n"
     ]
    }
   ],
   "source": [
    "with open('test_data.pickle', 'rb') as f:\n",
    "    graphs= pkl.load(f) \n",
    "\n",
    "MSEs = []\n",
    "for data in graphs:\n",
    "    torch_pred = torch_model(data)\n",
    "    torch_pred = torch_pred.detach().cpu().numpy().flatten()\n",
    "    hls_pred = hls_model.predict(data.hls_data)\n",
    "    MSE = mean_squared_error(torch_pred, hls_pred)\n",
    "    MSEs.append(MSE)\n",
    "    \n",
    "print(f\"MSEs: \\n {MSEs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62330a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter: 500\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now let's load some of tau3mu data from our group (Prof Mia Liu).\n",
    "This is still a smaller sample of the total data, but it's good enough. \n",
    "\n",
    "NOTE: this will take some time (<5mins)\n",
    "\"\"\"\n",
    "import timeit\n",
    "\n",
    "MSEs = []\n",
    "stages = [\"train\", \"valid\", \"test\"]\n",
    "# turn off debugging here\n",
    "torch_model.SetDebugMode(False)\n",
    "\n",
    "for stage in stages:\n",
    "    with open(f'tau3mu_data/test_BIG_data_{stage}.pickle', 'rb') as f:\n",
    "        graphs= pkl.load(f) \n",
    "        \n",
    "    counter = 0\n",
    "    start = timeit.default_timer()\n",
    "    for data in graphs:\n",
    "        # use counter to just keep track of the progress. Nothing fancy\n",
    "        if counter%500 ==0 and counter != 0:\n",
    "            print(f\"counter: {counter}\")\n",
    "        counter += 1\n",
    "        torch_pred = torch_model(data)\n",
    "        torch_pred = torch_pred.detach().cpu().numpy()\n",
    "        hls_pred = hls_model.predict(data.hls_data)\n",
    "        MSE = mean_squared_error(torch_pred, hls_pred)\n",
    "        MSEs.append(MSE)\n",
    "    end = timeit.default_timer()\n",
    "    print(f\"time taken: {(end - start)/ 60} mins\")\n",
    "MSEs = np.array(MSEs)\n",
    "print(f\"MSE means: {np.mean(MSEs)}\")\n",
    "print(f\"MSE max: {np.max(MSEs)}\")\n",
    "print(f\"n_total: {MSEs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now let's graph the MSE distribution\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_total = MSEs.shape[0]\n",
    "mean_val = np.mean(MSEs)\n",
    "\n",
    "plt.hist(MSEs, density=True, bins=50, label=f\"Mean value: {mean_val}\\n max val outlier removed\") \n",
    "plt.ylabel('Occurrence')\n",
    "plt.xlabel('MSE');\n",
    "plt.title(f'MSE of hls vs torch prediction (n_total: {n_total})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('MSEs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e149761",
   "metadata": {},
   "source": [
    "You can see from the graph above that the error is very small (order of magnitude -7). This will obviously get bigger once you use more realistic ap_fixed parameters, but this proves that the conversion itself is working as intended.\n",
    "\n",
    "So this is the latest progress on the pyg to hls conversion. The current model is only one layer out of eight pyg layers from the original Siqi's model. More work is on the way, but hopefully this gives you a good idea of how the conversion pipeline works. \n",
    "\n",
    "For any questions, please email me at yun@purdue.edu, or slack if you already have me on it.\n",
    "Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53405494",
   "metadata": {},
   "source": [
    "# Biography\n",
    "This walkthrough and other local files were taken from Mr Abd Elabd's code at https://github.com/abdelabd/manual_GNN_conversion <br />\n",
    "The hls4ml pyg support's starting code has been taken from Mr. Abd Elabd and Prof Javier Duarte's work: https://github.com/fastmachinelearning/hls4ml/tree/pyg_to_hls_rebase_w_dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94335a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
